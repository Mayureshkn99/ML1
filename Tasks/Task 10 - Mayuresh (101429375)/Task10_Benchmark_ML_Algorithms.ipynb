{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 10 : Benchmark Top ML Algorithms\n",
    "\n",
    "This task tests your ability to use different ML algorithms when solving a specific problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Predict Loan Eligibility for Dream Housing Finance company\n",
    "\n",
    "Dream Housing Finance company deals in all kinds of home loans. They have presence across all urban, semi urban and rural areas. Customer first applies for home loan and after that company validates the customer eligibility for loan.\n",
    "\n",
    "Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have provided a dataset to identify the customers segments that are eligible for loan amount so that they can specifically target these customers.\n",
    "\n",
    "Train: https://raw.githubusercontent.com/subashgandyer/datasets/main/loan_train.csv\n",
    "\n",
    "Test: https://raw.githubusercontent.com/subashgandyer/datasets/main/loan_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Requirements\n",
    "### You can have the following Classification models built using different ML algorithms\n",
    "- Decision Tree\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- Random Forest\n",
    "- Any other algorithm of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearchCV for finding the best model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Build models\n",
    "- ### Create Parameter Grid\n",
    "- ### Run GridSearchCV\n",
    "- ### Choose the best model with the best hyperparameter\n",
    "- ### Give the best accuracy\n",
    "- ### Also, benchmark the best accuracy that you could get for every classification algorithm asked above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your final output will be something like this:\n",
    "- Best algorithm accuracy\n",
    "- Best hyperparameter accuracy for every algorithm\n",
    "\n",
    "**Table 1 (Algorithm wise best model with best hyperparameter)**\n",
    "\n",
    "Algorithm   |     Accuracy   |   Hyperparameters\n",
    "- DT\n",
    "- KNN\n",
    "- LR\n",
    "- SVM\n",
    "- RF\n",
    "- anyother\n",
    "\n",
    "**Table 2 (Best overall)**\n",
    "\n",
    "Algorithm    |   Accuracy    |   Hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "- Submit Notebook containing all saved ran code with outputs\n",
    "- Document with the above two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the training dataset\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/subashgandyer/datasets/main/loan_train.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Showing data type\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Loan_ID\n",
    "\n",
    "data = data.drop(columns=[\"Loan_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Categorical columns\n",
    "\n",
    "cat_cols = []\n",
    "for column in data.columns:\n",
    "    if data[column].dtype==\"object\":\n",
    "        cat_cols.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: ['Male' 'Female' nan]\n",
      "Married: ['No' 'Yes' nan]\n",
      "Dependents: ['0' '1' '2' '3+' nan]\n",
      "Education: ['Graduate' 'Not Graduate']\n",
      "Self_Employed: ['No' 'Yes' nan]\n",
      "ApplicantIncome: [ 5849  4583  3000  2583  6000  5417  2333  3036  4006 12841  3200  2500\n",
      "  3073  1853  1299  4950  3596  3510  4887  2600  7660  5955  3365  3717\n",
      "  9560  2799  4226  1442  3750  4166  3167  4692  3500 12500  2275  1828\n",
      "  3667  3748  3600  1800  2400  3941  4695  3410  5649  5821  2645  4000\n",
      "  1928  3086  4230  4616 11500  2708  2132  3366  8080  3357  3029  2609\n",
      "  4945  5726 10750  7100  4300  3208  1875  4755  5266  1000  3333  3846\n",
      "  2395  1378  3988  2366  8566  5695  2958  6250  3273  4133  3620  6782\n",
      "  2484  1977  4188  1759  4288  4843 13650  4652  3816  3052 11417  7333\n",
      "  3800  2071  5316  2929  3572  7451  5050 14583  2214  5568 10408  5667\n",
      "  2137  2957  3692 23803  3865 10513  6080 20166  2014  2718  3459  4895\n",
      "  3316 14999  4200  5042  6950  2698 11757  2330 14866  1538 10000  4860\n",
      "  6277  2577  9166  2281  3254 39999  9538  2980  1863  7933  3089  4167\n",
      "  9323  3707  2439  2237  8000  1820 51763  3522  5708  4344  3497  2045\n",
      "  5516  6400  1916  4600 33846  3625 39147  2178  2383   674  9328  4885\n",
      " 12000  6033  3858  4191  3125  8333  1907  3416 11000  4923  3992  3917\n",
      "  4408  3244  3975  2479  3418  3430  7787  5703  3173  3850   150  3727\n",
      "  5000  4283  2221  4009  2971  7578  3250  4735  4758  2491  3716  3189\n",
      "  3155  5500  5746  3463  3812  3315  5819  2510  2965  3406  6050  9703\n",
      "  6608  2882  1809  1668  3427  2661 16250  3083  6045  5250 14683  4931\n",
      "  6083  2060  3481  7200  5166  4095  4708  4333  2876  3237 11146  2833\n",
      "  2620  3900  2750  3993  3103  4100  4053  3927  2301  1811 20667  3158\n",
      "  3704  4124  9508  3075  4400  3153  4416  6875  4666  2875  1625  2000\n",
      "  3762 20233  7667  2917  2927  2507  2473  3399  2058  3541  4342  3601\n",
      "  3166 15000  8666  4917  5818  4384  2935 63337  9833  5503  1830  4160\n",
      "  2647  2378  4554  2499  3523  6333  2625  9083  8750  2666  2423  3813\n",
      "  3875  5167  4723  4750  3013  6822  6216  5124  6325 19730 15759  5185\n",
      "  3062  2764  4817  4310  3069  5391  5941  7167  4566  2346  3010  5488\n",
      "  9167  9504  1993  3100  3276  3180  3033  3902  1500  2889  2755  1963\n",
      "  7441  4547  2167  2213  8300 81000  3867  6256  6096  2253  2149  2995\n",
      "  1600  1025  3246  5829  2720  7250 14880  4606  5935  2920  2717  8624\n",
      "  6500 12876  2425 10047  1926 10416  7142  3660  7901  4707 37719  3466\n",
      "  3539  3340  2769  2309  1958  3948  2483  7085  3859  4301  3708  4354\n",
      "  8334  2083  7740  3015  5191  2947 16692   210  3450  2653  4691  5532\n",
      " 16525  6700  2873 16667  4350  3095 10833  3547 18333  2435  2699  5333\n",
      "  3691 17263  3597  3326  4625  2895  6283   645  3159  4865  4050  3814\n",
      " 20833  3583 13262  3598  6065  3283  2130  5815  2031  3074  4683  3400\n",
      "  2192  5677  7948  4680 17500  3775  5285  2679  6783  4281  3588 11250\n",
      " 18165  2550  6133  3617  6417  4608  2138  3652  2239  3017  2768  3358\n",
      "  2526  2785  6633  2492  2454  3593  5468  2667 10139  3887  4180  3675\n",
      " 19484  5923  5800  8799  4467  3417  5116 16666  6125  6406  3087  3229\n",
      "  1782  3182  6540  1836  1880  2787  2297  2165  2726  9357 16120  3833\n",
      "  6383  2987  9963  5780   416  2894  3676  3987  3232  2900  4106  8072\n",
      "  7583]\n",
      "CoapplicantIncome: [0.00000000e+00 1.50800000e+03 2.35800000e+03 4.19600000e+03\n",
      " 1.51600000e+03 2.50400000e+03 1.52600000e+03 1.09680000e+04\n",
      " 7.00000000e+02 1.84000000e+03 8.10600000e+03 2.84000000e+03\n",
      " 1.08600000e+03 3.50000000e+03 5.62500000e+03 1.91100000e+03\n",
      " 1.91700000e+03 2.92500000e+03 2.25300000e+03 1.04000000e+03\n",
      " 2.08300000e+03 3.36900000e+03 1.66700000e+03 3.00000000e+03\n",
      " 2.06700000e+03 1.33000000e+03 1.45900000e+03 7.21000000e+03\n",
      " 1.66800000e+03 1.21300000e+03 2.33600000e+03 3.44000000e+03\n",
      " 2.27500000e+03 1.64400000e+03 1.16700000e+03 1.59100000e+03\n",
      " 2.20000000e+03 2.25000000e+03 2.85900000e+03 3.79600000e+03\n",
      " 3.44900000e+03 4.59500000e+03 2.25400000e+03 3.06600000e+03\n",
      " 1.87500000e+03 1.77400000e+03 4.75000000e+03 3.02200000e+03\n",
      " 4.00000000e+03 2.16600000e+03 1.88100000e+03 2.53100000e+03\n",
      " 2.00000000e+03 2.11800000e+03 4.16700000e+03 2.90000000e+03\n",
      " 5.65400000e+03 1.82000000e+03 2.30200000e+03 9.97000000e+02\n",
      " 3.54100000e+03 3.26300000e+03 3.80600000e+03 3.58300000e+03\n",
      " 7.54000000e+02 1.03000000e+03 1.12600000e+03 3.60000000e+03\n",
      " 2.33300000e+03 4.11400000e+03 2.28300000e+03 1.39800000e+03\n",
      " 2.14200000e+03 2.66700000e+03 8.98000000e+03 2.01400000e+03\n",
      " 1.64000000e+03 3.85000000e+03 2.56900000e+03 1.92900000e+03\n",
      " 7.75000000e+03 1.43000000e+03 2.03400000e+03 4.48600000e+03\n",
      " 1.42500000e+03 1.66600000e+03 8.30000000e+02 3.75000000e+03\n",
      " 1.04100000e+03 1.28000000e+03 1.44700000e+03 3.16600000e+03\n",
      " 3.33300000e+03 1.76900000e+03 7.36000000e+02 1.96400000e+03\n",
      " 1.61900000e+03 1.13000000e+04 1.45100000e+03 7.25000000e+03\n",
      " 5.06300000e+03 2.13800000e+03 5.29600000e+03 2.58300000e+03\n",
      " 2.36500000e+03 2.81600000e+03 2.50000000e+03 1.08300000e+03\n",
      " 1.25000000e+03 3.02100000e+03 9.83000000e+02 1.80000000e+03\n",
      " 1.77500000e+03 2.38300000e+03 1.71700000e+03 2.79100000e+03\n",
      " 1.01000000e+03 1.69500000e+03 2.05400000e+03 2.59800000e+03\n",
      " 1.77900000e+03 1.26000000e+03 5.00000000e+03 1.98300000e+03\n",
      " 5.70100000e+03 1.30000000e+03 4.41700000e+03 4.33300000e+03\n",
      " 1.84300000e+03 1.86800000e+03 3.89000000e+03 2.16700000e+03\n",
      " 7.10100000e+03 2.10000000e+03 4.25000000e+03 2.20900000e+03\n",
      " 3.44700000e+03 1.38700000e+03 1.81100000e+03 1.56000000e+03\n",
      " 1.85700000e+03 2.22300000e+03 1.84200000e+03 3.27400000e+03\n",
      " 2.42600000e+03 8.00000000e+02 9.85799988e+02 3.05300000e+03\n",
      " 2.41600000e+03 3.33400000e+03 2.54100000e+03 2.93400000e+03\n",
      " 1.75000000e+03 1.80300000e+03 1.86300000e+03 2.40500000e+03\n",
      " 2.13400000e+03 1.89000000e+02 1.59000000e+03 2.98500000e+03\n",
      " 4.98300000e+03 2.16000000e+03 2.45100000e+03 1.79300000e+03\n",
      " 1.83300000e+03 4.49000000e+03 6.88000000e+02 4.60000000e+03\n",
      " 1.58700000e+03 1.22900000e+03 2.33000000e+03 2.45800000e+03\n",
      " 3.23000000e+03 2.16800000e+03 4.58300000e+03 6.25000000e+03\n",
      " 5.05000000e+02 3.16700000e+03 3.66700000e+03 3.03300000e+03\n",
      " 5.26600000e+03 7.87300000e+03 1.98700000e+03 9.23000000e+02\n",
      " 4.99600000e+03 4.23200000e+03 1.60000000e+03 3.13600000e+03\n",
      " 2.41700000e+03 2.11500000e+03 1.62500000e+03 1.40000000e+03\n",
      " 4.84000000e+02 2.00000000e+04 2.40000000e+03 2.03300000e+03\n",
      " 3.23700000e+03 2.77300000e+03 1.41700000e+03 1.71900000e+03\n",
      " 4.30000000e+03 1.61200008e+01 2.34000000e+03 1.85100000e+03\n",
      " 1.12500000e+03 5.06400000e+03 1.99300000e+03 8.33300000e+03\n",
      " 1.21000000e+03 1.37600000e+03 1.71000000e+03 1.54200000e+03\n",
      " 1.25500000e+03 1.45600000e+03 1.73300000e+03 2.46600000e+03\n",
      " 4.08300000e+03 2.18800000e+03 1.66400000e+03 2.91700000e+03\n",
      " 2.07900000e+03 1.50000000e+03 4.64800000e+03 1.01400000e+03\n",
      " 1.87200000e+03 1.60300000e+03 3.15000000e+03 2.43600000e+03\n",
      " 2.78500000e+03 1.13100000e+03 2.15700000e+03 9.13000000e+02\n",
      " 1.70000000e+03 2.85700000e+03 4.41600000e+03 3.68300000e+03\n",
      " 5.62400000e+03 5.30200000e+03 1.48300000e+03 6.66700000e+03\n",
      " 3.01300000e+03 1.28700000e+03 2.00400000e+03 2.03500000e+03\n",
      " 6.66600000e+03 3.66600000e+03 3.42800000e+03 1.63200000e+03\n",
      " 1.91500000e+03 1.74200000e+03 1.42400000e+03 7.16600000e+03\n",
      " 2.08700000e+03 1.30200000e+03 5.50000000e+03 2.04200000e+03\n",
      " 3.90600000e+03 5.36000000e+02 2.84500000e+03 2.52400000e+03\n",
      " 6.63000000e+02 1.95000000e+03 1.78300000e+03 2.01600000e+03\n",
      " 2.37500000e+03 3.25000000e+03 4.26600000e+03 1.03200000e+03\n",
      " 2.66900000e+03 2.30600000e+03 2.42000000e+02 2.06400000e+03\n",
      " 4.61000000e+02 2.21000000e+03 2.73900000e+03 2.23200000e+03\n",
      " 3.38370000e+04 1.52200000e+03 3.41600000e+03 3.30000000e+03\n",
      " 1.00000000e+03 4.16670000e+04 2.79200000e+03 4.30100000e+03\n",
      " 3.80000000e+03 1.41100000e+03 2.40000000e+02]\n",
      "LoanAmount: [ nan 128.  66. 120. 141. 267.  95. 158. 168. 349.  70. 109. 200. 114.\n",
      "  17. 125. 100.  76. 133. 115. 104. 315. 116. 112. 151. 191. 122. 110.\n",
      "  35. 201.  74. 106. 320. 144. 184.  80.  47.  75. 134.  96.  88.  44.\n",
      " 286.  97. 135. 180.  99. 165. 258. 126. 312. 136. 172.  81. 187. 113.\n",
      " 176. 130. 111. 167. 265.  50. 210. 175. 131. 188.  25. 137. 160. 225.\n",
      " 216.  94. 139. 152. 118. 185. 154.  85. 259. 194.  93. 370. 182. 650.\n",
      " 102. 290.  84. 242. 129.  30. 244. 600. 255.  98. 275. 121.  63. 700.\n",
      "  87. 101. 495.  67.  73. 260. 108.  58.  48. 164. 170.  83.  90. 166.\n",
      " 124.  55.  59. 127. 214. 240.  72.  60. 138.  42. 280. 140. 155. 123.\n",
      " 279. 192. 304. 330. 150. 207. 436.  78.  54.  89. 143. 105. 132. 480.\n",
      "  56. 159. 300. 376. 117.  71. 490. 173.  46. 228. 308. 236. 570. 380.\n",
      " 296. 156. 103.  45.  65.  53. 360.  62. 218. 178. 239. 405. 148. 190.\n",
      " 149. 153. 162. 230.  86. 234. 246. 500. 186. 119. 107. 209. 208. 243.\n",
      "  40. 250. 311. 400. 161. 196. 324. 157. 145. 181.  26. 211.   9. 205.\n",
      "  36.  61. 146. 292. 142. 350. 496. 253.]\n",
      "Loan_Amount_Term: [360. 120. 240.  nan 180.  60. 300. 480.  36.  84.  12.]\n",
      "Credit_History: [ 1.  0. nan]\n",
      "Property_Area: ['Urban' 'Rural' 'Semiurban']\n",
      "Loan_Status: ['Y' 'N']\n"
     ]
    }
   ],
   "source": [
    "# Checking the possible values for each feature\n",
    "\n",
    "for column in data.columns:\n",
    "    print(f\"{column}: {data[column].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function for Label Encoding\n",
    "\n",
    "def label_encode_columns(df, columns, le):\n",
    "    for col in columns:\n",
    "        # fit the encoder on non-null values\n",
    "        le.fit(df[col][df[col].notnull()])\n",
    "        \n",
    "        # transform the column and preserve the NaN values\n",
    "        df[col] = df[col].map(lambda x: x if pd.isna(x) else le.transform([x])[0])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0       1.0      0.0         0.0          0            0.0             5849   \n",
       "1       1.0      1.0         1.0          0            0.0             4583   \n",
       "2       1.0      1.0         0.0          0            1.0             3000   \n",
       "3       1.0      1.0         0.0          1            0.0             2583   \n",
       "4       1.0      0.0         0.0          0            0.0             6000   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "609     0.0      0.0         0.0          0            0.0             2900   \n",
       "610     1.0      1.0         3.0          0            0.0             4106   \n",
       "611     1.0      1.0         1.0          0            0.0             8072   \n",
       "612     1.0      1.0         2.0          0            0.0             7583   \n",
       "613     0.0      0.0         0.0          0            1.0             4583   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                  0.0         NaN             360.0             1.0   \n",
       "1               1508.0       128.0             360.0             1.0   \n",
       "2                  0.0        66.0             360.0             1.0   \n",
       "3               2358.0       120.0             360.0             1.0   \n",
       "4                  0.0       141.0             360.0             1.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "609                0.0        71.0             360.0             1.0   \n",
       "610                0.0        40.0             180.0             1.0   \n",
       "611              240.0       253.0             360.0             1.0   \n",
       "612                0.0       187.0             360.0             1.0   \n",
       "613                0.0       133.0             360.0             0.0   \n",
       "\n",
       "     Property_Area  \n",
       "0                2  \n",
       "1                0  \n",
       "2                2  \n",
       "3                2  \n",
       "4                2  \n",
       "..             ...  \n",
       "609              0  \n",
       "610              0  \n",
       "611              2  \n",
       "612              2  \n",
       "613              1  \n",
       "\n",
       "[614 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "df = label_encode_columns(data, cat_cols, le)\n",
    "y = df[\"Loan_Status\"]\n",
    "df = df.drop(columns=[\"Loan_Status\"])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Iterative Imputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputer.fit(df)\n",
    "df_transform = imputer.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = MinMaxScaler().fit_transform(df_transform)\n",
    "X = pd.DataFrame(data=df)\n",
    "feature_name = list(X.columns)\n",
    "num_feats = len(feature_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    \n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    \n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    \n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    \n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_support, cor_feature = cor_selector(X, y, num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_selector(X, y, num_feats):\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=num_feats)\n",
    "    bestfeatures.fit(X,y)\n",
    "    chi_support=bestfeatures.get_support()\n",
    "    chi_feature=X.loc[:,chi_support].columns.tolist()\n",
    "    return chi_support, chi_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_support, chi_feature = chi_squared_selector(X, y,num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_selector(X, y, num_feats):\n",
    "    rfe_selector= RFE(estimator=LogisticRegression(),n_features_to_select=num_feats,step=10,verbose=5)\n",
    "    rfe_selector.fit(X, y)\n",
    "    rfe_support=rfe_selector.get_support()\n",
    "    rfe_feature=X.loc[:, rfe_support].columns.tolist()\n",
    "    return rfe_support, rfe_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_support, rfe_feature = rfe_selector(X, y,num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_log_reg_selector(X, y, num_feats):\n",
    "    lr_selector=SelectFromModel(LogisticRegression(random_state=0),max_features=num_feats)\n",
    "    lr_selector.fit(X, y)\n",
    "    lr_support=lr_selector.get_support()\n",
    "    lr_feature=X.loc[:, lr_support].columns.tolist()\n",
    "    return lr_support, lr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_lr_support, embedded_lr_feature = embedded_log_reg_selector(X, y, num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_rf_selector(X, y, num_feats):\n",
    "    rf_selector=SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=0),max_features=num_feats)\n",
    "    \n",
    "    rf_selector.fit(X,y)\n",
    "    rf_support=rf_selector.get_support()\n",
    "    rf_feature=X.loc[:,rf_support].columns.tolist()\n",
    "    \n",
    "    return rf_support, rf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_rf_support, embeded_rf_feature = embedded_rf_selector(X, y, num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_lgbm_selector(X, y, num_feats):\n",
    "    lgbc=LGBMClassifier(n_estimators=500,learning_rate=.05,num_leaves=32,colsample_bytree=.2,\n",
    "                       reg_alpha=3,reg_lambda=1,min_split_gain=.01,min_child_weight=40, random_state=0)\n",
    "    lgb_selector=SelectFromModel(lgbc,max_features=num_feats)\n",
    "    lgb_selector.fit(X,y)\n",
    "    lgb_support=lgb_selector.get_support()\n",
    "    lgb_feature=X.loc[:,lgb_support].columns.tolist()\n",
    "    return lgb_support, lgb_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_lgbm_support, embeded_lgbm_feature = embedded_lgbm_selector(X, y, num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Chi-2</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Pearson  Chi-2   RFE  Logistic  Random Forest  LightGBM  Total\n",
       "1         9     True   True  True      True           True      True      6\n",
       "2         7     True   True  True      True           True      True      6\n",
       "3         6     True   True  True      True           True      True      6\n",
       "4         5     True   True  True     False           True      True      5\n",
       "5        10     True   True  True     False          False      True      4\n",
       "6         8     True   True  True     False          False      True      4\n",
       "7         4     True   True  True     False          False      True      4\n",
       "8         3     True   True  True     False          False      True      4\n",
       "9         2     True   True  True     False          False      True      4\n",
       "10        1     True   True  True     False          False      True      4\n",
       "11        0     True   True  True     False          False      True      4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistic':embedded_lr_support,\n",
    "                                    'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgbm_support})\n",
    "# count the selected times for each feature\n",
    "feature_selection_df['Total'] = np.sum(feature_selection_df.iloc[:,1:], axis=1)\n",
    "# display the top 100\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "feature_selection_df.head(num_feats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8292682926829268\n",
      "Confusion Matrix:\n",
      " [[14 19]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "# Defining and Training the logistic Regression Model\n",
    "lr_model = LogisticRegression(random_state=0)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the Logistic Regression Model\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_score = lr_model.score(X_test, y_test)\n",
    "print(\"Accuracy: \", lr_score)\n",
    "\n",
    "# Confusion Matrix\n",
    "lr_cm = confusion_matrix(y_test,lr_predictions)\n",
    "print(\"Confusion Matrix:\\n\", lr_cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best parameters: {'C': 1, 'class_weight': None, 'fit_intercept': True, 'tol': 0.001}\n",
      "Accuracy: 0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to tune with GridSearch\n",
    "param_grid = {'C': [1,5, 20,100,500],\n",
    "              'tol': [0.001, 0.0001, 0.00001], \n",
    "              'class_weight': ['balanced', None],\n",
    "              'fit_intercept': [True, False]}\n",
    "\n",
    "# Training the Model\n",
    "lr_model = LogisticRegression(random_state=0)\n",
    "lr_gs = GridSearchCV(lr_model,\n",
    "                           param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Applying the Model\n",
    "lr_gs.fit(X_train, y_train)\n",
    "lr_gs_predictions = lr_gs.predict(X_test)\n",
    "lr_gs_score = lr_gs.score(X_test, y_test)\n",
    "\n",
    "# Optimum values values for the hyperparameters and the improved accuracy score\n",
    "print(\"Best parameters:\", lr_gs.best_params_)\n",
    "print(\"Accuracy:\", lr_gs_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree has 197 nodes with maximum depth 17.\n",
      "Train ROC AUC Score: 1.0\n",
      "Test ROC AUC  Score: 0.6601010101010101\n",
      "Baseline ROC AUC: 0.5\n",
      "Accuracy: 0.6991869918699187\n",
      "Confusion Matrix:\n",
      " [[19 14]\n",
      " [23 67]]\n"
     ]
    }
   ],
   "source": [
    "#Defining and Training the Decision Tree Model\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#Node count and Maximum depth of the tree\n",
    "print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')\n",
    "\n",
    "#Make probability predictions\n",
    "train_probs = tree.predict_proba(X_train)[:,1]\n",
    "probs = tree.predict_proba(X_test)[:,1]\n",
    "\n",
    "train_predictions = tree.predict(X_train)\n",
    "predictions = tree.predict(X_test)\n",
    "\n",
    "#Plot ROC AUC Score to assess Decision Tree Performance\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(y_test, probs)}')\n",
    "print(f'Baseline ROC AUC: {roc_auc_score(y_test, [1 for _ in range(len(y_test))])}')\n",
    "\n",
    "\n",
    "# Calculate the accuracy score\n",
    "y_pred = tree.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {dt_accuracy}\")\n",
    "\n",
    "#Decision Tree Confusional Matrix\n",
    "dt_cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", dt_cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to tune with GridSearch\n",
    "param_dict = {'criterion':['gini', 'entropy'],\n",
    "              'max_depth':range(1,10),\n",
    "              'min_samples_split':range(2,10),\n",
    "              'min_samples_leaf':range(1,5)}\n",
    "\n",
    " # Training the Model           \n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt_gs = GridSearchCV(dt,\n",
    "                       param_grid=param_dict,\n",
    "                       scoring='accuracy',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Applying the Model\n",
    "dt_gs.fit(X_train, y_train)\n",
    "dt_gs_predictions = dt_gs.predict(X_test)\n",
    "dt_gs_accuracy = accuracy_score(y_test, dt_gs_predictions)\n",
    "\n",
    "#Print out the best parameters by using GridSearchCV and the best score of the model\n",
    "print(\"Best parameters:\", dt_gs.best_params_)\n",
    "print(\"Accuracy:\", dt_gs_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 203\n",
      "Average maximum depth 17\n",
      "Train ROC AUC Score: 0.9999999999999999\n",
      "Test ROC AUC  Score: 0.7585858585858586\n",
      "Baseline ROC AUC: 0.5\n",
      "Accuracy: 0.7804878048780488\n",
      "Confusion Matrix:\n",
      " [[15 18]\n",
      " [ 9 81]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Defining and Training the Random Forest Classifiesr\n",
    "rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                  random_state=0,\n",
    "                                  max_features='sqrt',\n",
    "                                  n_jobs=-1,\n",
    "                                  verbose=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#Node count and Maximum depth of the tree\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in rf_model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')\n",
    "\n",
    "#Make Random Forest predictions\n",
    "train_rf_predictions = rf_model.predict(X_train)\n",
    "train_rf_probs = rf_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Plot ROC AUC Score\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_rf_probs)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(y_test, rf_probs)}')\n",
    "print(f'Baseline ROC AUC: {roc_auc_score(y_test, [1 for _ in range(len(y_test))])}')\n",
    "\n",
    "# Calculate the accuracy score\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "\n",
    "#Random Forest Confusion Matrix\n",
    "rf_cm = confusion_matrix(y_test, rf_predictions)\n",
    "print(\"Confusion Matrix:\\n\", rf_cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to tune with GridSearch\n",
    "param_grid = {'n_estimators': [10, 50, 100],\n",
    "              'max_depth': [None, 10, 20],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "#Train and Fit the Model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf_gs = GridSearchCV(rf,\n",
    "                       param_grid,\n",
    "                       scoring=\"accuracy\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "rf_gs_pred = rf_gs.predict(X_test)\n",
    "rf_gs_accuracy = accuracy_score(y_test, rf_gs_pred)\n",
    "\n",
    "# Optimum values values for the hyperparameters and the improved score\n",
    "print(f\"Best parameters: {rf_gs.best_params_}\")\n",
    "print(f\"Accuracy: {rf_gs_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7886178861788617\n",
      "Confusion Matrix:\n",
      " [[14 19]\n",
      " [ 7 83]]\n"
     ]
    }
   ],
   "source": [
    "# Defining and Training the Stochastic Gradient Descent Model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the Stochastic Gradient Descent Model\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(\"Accuracy: \", knn_accuracy)\n",
    "\n",
    "# Confusion Matrix\n",
    "knn_cm = confusion_matrix(y_test, knn_predictions)\n",
    "print(\"Confusion Matrix:\\n\", knn_cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters: {'algorithm': 'auto', 'leaf_size': 30, 'weights': 'uniform'}\n",
      "Accuracy: 0.7886178861788617\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to tune with GridSearch\n",
    "param_grid = {'weights': ['uniform', 'distance'],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'leaf_size': [30, 35]}\n",
    "\n",
    "# Training the Model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_gs = GridSearchCV(knn_model,\n",
    "                           param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Applying the Model\n",
    "knn_gs.fit(X_train, y_train)\n",
    "knn_gs_predictions = knn_gs.predict(X_test)\n",
    "knn_gs_accuracy = accuracy_score(y_test, knn_gs_predictions)\n",
    "\n",
    "# Optimum values values for the hyperparameters and the improved accuracy score\n",
    "print(\"Best parameters:\", knn_gs.best_params_)\n",
    "print(\"Accuracy:\", knn_gs_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8292682926829268\n",
      "Confusion Matrix:\n",
      " [[14 19]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "# Defining and Training the Support Vector Machine Model\n",
    "svm_model = SVC(random_state=0)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the Stochastic Gradient Descent Model\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_score = svm_model.score(X_test, y_test)\n",
    "print(\"Accuracy: \", svm_score)\n",
    "\n",
    "svm_cm = confusion_matrix(y_test,svm_predictions)\n",
    "print(\"Confusion Matrix:\\n\", svm_cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Best parameters: {'C': 1, 'gamma': 0.001, 'kernel': 'linear', 'shrinking': True}\n",
      "Accuracy: 0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters to tune with GridSearch\n",
    "param_grid = {'C': [1,5, 20,100,500],\n",
    "              'gamma': [.001, .01, .1,1, 'scale', 'auto'],\n",
    "              'kernel': ['linear', 'rbf'],\n",
    "              'shrinking': [True, False]}\n",
    "\n",
    "# Training the Model\n",
    "svm_model = SVC(random_state=0)\n",
    "svm_gs = GridSearchCV(svm_model,\n",
    "                           param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Applying the Model\n",
    "svm_gs.fit(X_train, y_train)\n",
    "svm_gs_predictions=svm_gs.predict(X_test)\n",
    "svm_gs_accuracy = accuracy_score(y_test, svm_gs_predictions)\n",
    "\n",
    "# Optimum values values for the hyperparameters and the improved accuracy score\n",
    "print(\"Best parameters:\", svm_gs.best_params_)\n",
    "print(\"Accuracy:\", svm_gs_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary of all the models\n",
    "\n",
    "models = {'lr': lr_gs,\n",
    "          'knn': knn_gs,\n",
    "          'dt': dt_gs,\n",
    "          'svm': svm_gs,\n",
    "          'rf': rf_gs\n",
    "         }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the individual models and make base predictions\n",
    "\n",
    "base_model_train_predictions = []\n",
    "for algo, model in models.items():\n",
    "    # Fit on the training dataset\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on the hold-out dataset\n",
    "    yhat = model.predict(X_test)\n",
    "    # Store predictions for meta-model's use\n",
    "    yhat = yhat.reshape(len(yhat), 1)\n",
    "    base_model_train_predictions.append(yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the base model output\n",
    "\n",
    "base_model_train_predictions = np.hstack(base_model_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the META model\n",
    "\n",
    "blender = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender.fit(base_model_train_predictions, y_test)\n",
    "blender_predictions = blender.predict(base_model_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8292682926829268"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of the blender model\n",
    "\n",
    "accuracy_score(y_test, blender_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>LP002971</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4009</td>\n",
       "      <td>1777</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>LP002975</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>LP002980</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3250</td>\n",
       "      <td>1993</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>LP002986</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>LP002989</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001015   Male     Yes          0      Graduate            No   \n",
       "1    LP001022   Male     Yes          1      Graduate            No   \n",
       "2    LP001031   Male     Yes          2      Graduate            No   \n",
       "3    LP001035   Male     Yes          2      Graduate            No   \n",
       "4    LP001051   Male      No          0  Not Graduate            No   \n",
       "..        ...    ...     ...        ...           ...           ...   \n",
       "362  LP002971   Male     Yes         3+  Not Graduate           Yes   \n",
       "363  LP002975   Male     Yes          0      Graduate            No   \n",
       "364  LP002980   Male      No          0      Graduate            No   \n",
       "365  LP002986   Male     Yes          0      Graduate            No   \n",
       "366  LP002989   Male      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5720                  0       110.0             360.0   \n",
       "1               3076               1500       126.0             360.0   \n",
       "2               5000               1800       208.0             360.0   \n",
       "3               2340               2546       100.0             360.0   \n",
       "4               3276                  0        78.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "362             4009               1777       113.0             360.0   \n",
       "363             4158                709       115.0             360.0   \n",
       "364             3250               1993       126.0             360.0   \n",
       "365             5000               2393       158.0             360.0   \n",
       "366             9200                  0        98.0             180.0   \n",
       "\n",
       "     Credit_History Property_Area  \n",
       "0               1.0         Urban  \n",
       "1               1.0         Urban  \n",
       "2               1.0         Urban  \n",
       "3               NaN         Urban  \n",
       "4               1.0         Urban  \n",
       "..              ...           ...  \n",
       "362             1.0         Urban  \n",
       "363             1.0         Urban  \n",
       "364             NaN     Semiurban  \n",
       "365             1.0         Rural  \n",
       "366             1.0         Rural  \n",
       "\n",
       "[367 rows x 12 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the test dataset\n",
    "\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/subashgandyer/datasets/main/loan_test.csv\")\n",
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Loan_ID\n",
    "\n",
    "test.drop(columns=[\"Loan_ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               11\n",
       "Married               0\n",
       "Dependents           10\n",
       "Education             0\n",
       "Self_Employed        23\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount            5\n",
       "Loan_Amount_Term      6\n",
       "Credit_History       29\n",
       "Property_Area         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4009</td>\n",
       "      <td>1777</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3250</td>\n",
       "      <td>1993</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0       1.0        1         0.0          0            0.0             5720   \n",
       "1       1.0        1         1.0          0            0.0             3076   \n",
       "2       1.0        1         2.0          0            0.0             5000   \n",
       "3       1.0        1         2.0          0            0.0             2340   \n",
       "4       1.0        0         0.0          1            0.0             3276   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "362     1.0        1         3.0          1            1.0             4009   \n",
       "363     1.0        1         0.0          0            0.0             4158   \n",
       "364     1.0        0         0.0          0            0.0             3250   \n",
       "365     1.0        1         0.0          0            0.0             5000   \n",
       "366     1.0        0         0.0          0            1.0             9200   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                    0       110.0             360.0             1.0   \n",
       "1                 1500       126.0             360.0             1.0   \n",
       "2                 1800       208.0             360.0             1.0   \n",
       "3                 2546       100.0             360.0             NaN   \n",
       "4                    0        78.0             360.0             1.0   \n",
       "..                 ...         ...               ...             ...   \n",
       "362               1777       113.0             360.0             1.0   \n",
       "363                709       115.0             360.0             1.0   \n",
       "364               1993       126.0             360.0             NaN   \n",
       "365               2393       158.0             360.0             1.0   \n",
       "366                  0        98.0             180.0             1.0   \n",
       "\n",
       "     Property_Area  \n",
       "0                2  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                2  \n",
       "..             ...  \n",
       "362              2  \n",
       "363              2  \n",
       "364              1  \n",
       "365              0  \n",
       "366              0  \n",
       "\n",
       "[367 rows x 11 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "test = label_encode_columns(test, cat_cols[:-1], le)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   1.        ,   0.        , ..., 360.        ,\n",
       "          1.        ,   2.        ],\n",
       "       [  1.        ,   1.        ,   1.        , ..., 360.        ,\n",
       "          1.        ,   2.        ],\n",
       "       [  1.        ,   1.        ,   2.        , ..., 360.        ,\n",
       "          1.        ,   2.        ],\n",
       "       ...,\n",
       "       [  1.        ,   0.        ,   0.        , ..., 360.        ,\n",
       "          0.80549133,   1.        ],\n",
       "       [  1.        ,   1.        ,   0.        , ..., 360.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  1.        ,   0.        ,   0.        , ..., 180.        ,\n",
       "          1.        ,   0.        ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Iterative Imputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputer.fit(test)\n",
    "test_transform = imputer.transform(test)\n",
    "test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157088</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042411</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.187739</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068938</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.106083</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.798226</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095785</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055274</td>\n",
       "      <td>0.074042</td>\n",
       "      <td>0.162835</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057329</td>\n",
       "      <td>0.029542</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044810</td>\n",
       "      <td>0.083042</td>\n",
       "      <td>0.187739</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.805491</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068938</td>\n",
       "      <td>0.099708</td>\n",
       "      <td>0.249042</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1         2    3    4         5         6         7         8   \\\n",
       "0    1.0  1.0  0.000000  0.0  0.0  0.078865  0.000000  0.157088  0.746835   \n",
       "1    1.0  1.0  0.333333  0.0  0.0  0.042411  0.062500  0.187739  0.746835   \n",
       "2    1.0  1.0  0.666667  0.0  0.0  0.068938  0.075000  0.344828  0.746835   \n",
       "3    1.0  1.0  0.666667  0.0  0.0  0.032263  0.106083  0.137931  0.746835   \n",
       "4    1.0  0.0  0.000000  1.0  0.0  0.045168  0.000000  0.095785  0.746835   \n",
       "..   ...  ...       ...  ...  ...       ...       ...       ...       ...   \n",
       "362  1.0  1.0  1.000000  1.0  1.0  0.055274  0.074042  0.162835  0.746835   \n",
       "363  1.0  1.0  0.000000  0.0  0.0  0.057329  0.029542  0.166667  0.746835   \n",
       "364  1.0  0.0  0.000000  0.0  0.0  0.044810  0.083042  0.187739  0.746835   \n",
       "365  1.0  1.0  0.000000  0.0  0.0  0.068938  0.099708  0.249042  0.746835   \n",
       "366  1.0  0.0  0.000000  0.0  1.0  0.126846  0.000000  0.134100  0.367089   \n",
       "\n",
       "           9    10  \n",
       "0    1.000000  1.0  \n",
       "1    1.000000  1.0  \n",
       "2    1.000000  1.0  \n",
       "3    0.798226  1.0  \n",
       "4    1.000000  1.0  \n",
       "..        ...  ...  \n",
       "362  1.000000  1.0  \n",
       "363  1.000000  1.0  \n",
       "364  0.805491  0.5  \n",
       "365  1.000000  0.0  \n",
       "366  1.000000  0.0  \n",
       "\n",
       "[367 rows x 11 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = MinMaxScaler().fit_transform(test_transform)\n",
    "test = pd.DataFrame(data=test)\n",
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the blender model to make predictions\n",
    "\n",
    "base_model_train_predictions = []\n",
    "for algo, model in models.items():\n",
    "    # Predict on the hold-out dataset\n",
    "    yhat = model.predict(test)\n",
    "    # Store predictions for meta-model's use\n",
    "    yhat = yhat.reshape(len(yhat), 1)\n",
    "    base_model_train_predictions.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the base predictions\n",
    "\n",
    "base_model_train_predictions = np.hstack(base_model_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using base predictions to obtain final predictions\n",
    "\n",
    "blender_predictions = blender.predict(base_model_train_predictions)\n",
    "blender_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ab04ef9f3ed96eb7f9e19d04b0a7d73aeac73882eb3637be5aab00647ed79ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
